{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNKcLRyk53HInq/z4InVBci",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cerabbite/Easy-conalng/blob/main/Word.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each word in the top 10.000 most used English, Spanish, Japanese and Chinese words. There will be 100-1.000 sample sentences with those words (written in using the english alphabet). Using these sentences this script is going to work out how related words are."
      ],
      "metadata": {
        "id": "32YGG-XhZ2nR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXnCOjDzXq84"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "#!pip install keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import json\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset to python\n",
        "with open('Sarcasm_Headlines_Dataset_v2 - Copy.json', 'r') as f:\n",
        "  info = f.readlines()\n",
        "\n",
        "datastore = []\n",
        "for i in info:\n",
        "  datastore.append(json.loads(i))\n",
        "\n",
        "\n",
        "sentences = []\n",
        "labels = []\n",
        "urls = []\n",
        "for item in datastore:\n",
        "  sentences.append(item['headline'])\n",
        "  labels.append(item['is_sarcastic'])\n",
        "  urls.append(item['article_link'])"
      ],
      "metadata": {
        "id": "4mCSxt2EG-Nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables\n",
        "vocab_size = 15000\n",
        "embedding_dim = 16\n",
        "max_length = 100\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_size = 20000"
      ],
      "metadata": {
        "id": "e38RPrkaAeiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seperate training from testing\n",
        "training_sentences = sentences[0:training_size]\n",
        "testing_sentences = sentences[training_size:]\n",
        "training_labels = labels[0:training_size]\n",
        "testing_labels = labels[training_size:]"
      ],
      "metadata": {
        "id": "lNTCN0yi7xGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "\"\"\"sentences = [\n",
        "             'I love my dog',\n",
        "             'I love my cat',\n",
        "             'You love my dog!',\n",
        "             'Do you think my dog is amazing?'\n",
        "]\"\"\"\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "#print(word_index)\n",
        "print(training_padded[0])\n",
        "print(training_padded.shape)"
      ],
      "metadata": {
        "id": "Q8theL_qZn-A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a447840-7780-4814-88c5-f91fdfdb2183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  328 12776   799  3405  2404    47   389  2214 12777     6  2614  8863\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n",
            "(20000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "print(testing_padded[0])\n",
        "print(testing_padded.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H2vOL1gfKSc",
        "outputId": "81b1a702-4192-49be-ae07-a3338d3d2a60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[    1  1100  6663  9423    30 11505  2439     5   519   109     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n",
            "(6711, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train neural network\n",
        "training_padded = np.array(training_padded)\n",
        "training_labels = np.array(training_labels)\n",
        "testing_padded = np.array(testing_padded)\n",
        "testing_labels = np.array(testing_labels)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "                             tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                             tf.keras.layers.Dense(24, activation='relu'),\n",
        "                             tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7XejK7y_aX5",
        "outputId": "1cc6a744-ab65-4304-c4c9-1879ace57420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "625/625 - 4s - loss: 0.6730 - accuracy: 0.5688 - val_loss: 0.6205 - val_accuracy: 0.6005 - 4s/epoch - 6ms/step\n",
            "Epoch 2/50\n",
            "625/625 - 3s - loss: 0.4559 - accuracy: 0.8154 - val_loss: 0.3896 - val_accuracy: 0.8431 - 3s/epoch - 5ms/step\n",
            "Epoch 3/50\n",
            "625/625 - 3s - loss: 0.3073 - accuracy: 0.8820 - val_loss: 0.3590 - val_accuracy: 0.8464 - 3s/epoch - 5ms/step\n",
            "Epoch 4/50\n",
            "625/625 - 3s - loss: 0.2479 - accuracy: 0.9042 - val_loss: 0.3717 - val_accuracy: 0.8349 - 3s/epoch - 5ms/step\n",
            "Epoch 5/50\n",
            "625/625 - 3s - loss: 0.2079 - accuracy: 0.9223 - val_loss: 0.3433 - val_accuracy: 0.8581 - 3s/epoch - 5ms/step\n",
            "Epoch 6/50\n",
            "625/625 - 3s - loss: 0.1766 - accuracy: 0.9348 - val_loss: 0.3721 - val_accuracy: 0.8470 - 3s/epoch - 5ms/step\n",
            "Epoch 7/50\n",
            "625/625 - 3s - loss: 0.1498 - accuracy: 0.9478 - val_loss: 0.3634 - val_accuracy: 0.8574 - 3s/epoch - 5ms/step\n",
            "Epoch 8/50\n",
            "625/625 - 3s - loss: 0.1291 - accuracy: 0.9564 - val_loss: 0.3847 - val_accuracy: 0.8534 - 3s/epoch - 5ms/step\n",
            "Epoch 9/50\n",
            "625/625 - 3s - loss: 0.1133 - accuracy: 0.9620 - val_loss: 0.4000 - val_accuracy: 0.8525 - 3s/epoch - 4ms/step\n",
            "Epoch 10/50\n",
            "625/625 - 3s - loss: 0.0978 - accuracy: 0.9678 - val_loss: 0.4240 - val_accuracy: 0.8489 - 3s/epoch - 4ms/step\n",
            "Epoch 11/50\n",
            "625/625 - 3s - loss: 0.0862 - accuracy: 0.9724 - val_loss: 0.4486 - val_accuracy: 0.8504 - 3s/epoch - 5ms/step\n",
            "Epoch 12/50\n",
            "625/625 - 3s - loss: 0.0744 - accuracy: 0.9765 - val_loss: 0.4737 - val_accuracy: 0.8473 - 3s/epoch - 5ms/step\n",
            "Epoch 13/50\n",
            "625/625 - 3s - loss: 0.0641 - accuracy: 0.9809 - val_loss: 0.5243 - val_accuracy: 0.8397 - 3s/epoch - 5ms/step\n",
            "Epoch 14/50\n",
            "625/625 - 3s - loss: 0.0573 - accuracy: 0.9832 - val_loss: 0.5452 - val_accuracy: 0.8435 - 3s/epoch - 4ms/step\n",
            "Epoch 15/50\n",
            "625/625 - 3s - loss: 0.0486 - accuracy: 0.9869 - val_loss: 0.5697 - val_accuracy: 0.8418 - 3s/epoch - 5ms/step\n",
            "Epoch 16/50\n",
            "625/625 - 3s - loss: 0.0428 - accuracy: 0.9875 - val_loss: 0.6091 - val_accuracy: 0.8409 - 3s/epoch - 5ms/step\n",
            "Epoch 17/50\n",
            "625/625 - 3s - loss: 0.0364 - accuracy: 0.9909 - val_loss: 0.6441 - val_accuracy: 0.8377 - 3s/epoch - 5ms/step\n",
            "Epoch 18/50\n",
            "625/625 - 3s - loss: 0.0337 - accuracy: 0.9910 - val_loss: 0.6884 - val_accuracy: 0.8349 - 3s/epoch - 4ms/step\n",
            "Epoch 19/50\n",
            "625/625 - 3s - loss: 0.0295 - accuracy: 0.9929 - val_loss: 0.7302 - val_accuracy: 0.8328 - 3s/epoch - 4ms/step\n",
            "Epoch 20/50\n",
            "625/625 - 3s - loss: 0.0256 - accuracy: 0.9933 - val_loss: 0.7641 - val_accuracy: 0.8282 - 3s/epoch - 4ms/step\n",
            "Epoch 21/50\n",
            "625/625 - 3s - loss: 0.0216 - accuracy: 0.9948 - val_loss: 0.7987 - val_accuracy: 0.8257 - 3s/epoch - 4ms/step\n",
            "Epoch 22/50\n",
            "625/625 - 3s - loss: 0.0215 - accuracy: 0.9944 - val_loss: 0.8435 - val_accuracy: 0.8258 - 3s/epoch - 4ms/step\n",
            "Epoch 23/50\n",
            "625/625 - 3s - loss: 0.0168 - accuracy: 0.9959 - val_loss: 0.8754 - val_accuracy: 0.8237 - 3s/epoch - 5ms/step\n",
            "Epoch 24/50\n",
            "625/625 - 3s - loss: 0.0147 - accuracy: 0.9969 - val_loss: 0.9414 - val_accuracy: 0.8218 - 3s/epoch - 4ms/step\n",
            "Epoch 25/50\n",
            "625/625 - 3s - loss: 0.0132 - accuracy: 0.9973 - val_loss: 0.9929 - val_accuracy: 0.8206 - 3s/epoch - 4ms/step\n",
            "Epoch 26/50\n",
            "625/625 - 3s - loss: 0.0118 - accuracy: 0.9972 - val_loss: 1.0046 - val_accuracy: 0.8225 - 3s/epoch - 5ms/step\n",
            "Epoch 27/50\n",
            "625/625 - 3s - loss: 0.0102 - accuracy: 0.9977 - val_loss: 1.0460 - val_accuracy: 0.8197 - 3s/epoch - 4ms/step\n",
            "Epoch 28/50\n",
            "625/625 - 3s - loss: 0.0089 - accuracy: 0.9981 - val_loss: 1.1221 - val_accuracy: 0.8194 - 3s/epoch - 4ms/step\n",
            "Epoch 29/50\n",
            "625/625 - 3s - loss: 0.0075 - accuracy: 0.9984 - val_loss: 1.1680 - val_accuracy: 0.8187 - 3s/epoch - 5ms/step\n",
            "Epoch 30/50\n",
            "625/625 - 3s - loss: 0.0078 - accuracy: 0.9979 - val_loss: 1.1817 - val_accuracy: 0.8158 - 3s/epoch - 4ms/step\n",
            "Epoch 31/50\n",
            "625/625 - 3s - loss: 0.0065 - accuracy: 0.9984 - val_loss: 1.3606 - val_accuracy: 0.8170 - 3s/epoch - 5ms/step\n",
            "Epoch 32/50\n",
            "625/625 - 3s - loss: 0.0062 - accuracy: 0.9987 - val_loss: 1.3097 - val_accuracy: 0.8166 - 3s/epoch - 4ms/step\n",
            "Epoch 33/50\n",
            "625/625 - 3s - loss: 0.0045 - accuracy: 0.9992 - val_loss: 1.3456 - val_accuracy: 0.8194 - 3s/epoch - 4ms/step\n",
            "Epoch 34/50\n",
            "625/625 - 3s - loss: 0.0040 - accuracy: 0.9993 - val_loss: 1.3619 - val_accuracy: 0.8139 - 3s/epoch - 4ms/step\n",
            "Epoch 35/50\n",
            "625/625 - 3s - loss: 0.0043 - accuracy: 0.9990 - val_loss: 1.4129 - val_accuracy: 0.8163 - 3s/epoch - 4ms/step\n",
            "Epoch 36/50\n",
            "625/625 - 2s - loss: 0.0032 - accuracy: 0.9994 - val_loss: 1.4860 - val_accuracy: 0.8191 - 2s/epoch - 4ms/step\n",
            "Epoch 37/50\n",
            "625/625 - 3s - loss: 0.0028 - accuracy: 0.9994 - val_loss: 1.5078 - val_accuracy: 0.8142 - 3s/epoch - 4ms/step\n",
            "Epoch 38/50\n",
            "625/625 - 3s - loss: 0.0028 - accuracy: 0.9997 - val_loss: 1.5591 - val_accuracy: 0.8152 - 3s/epoch - 4ms/step\n",
            "Epoch 39/50\n",
            "625/625 - 3s - loss: 0.0030 - accuracy: 0.9994 - val_loss: 1.5761 - val_accuracy: 0.8151 - 3s/epoch - 4ms/step\n",
            "Epoch 40/50\n",
            "625/625 - 3s - loss: 0.0019 - accuracy: 0.9998 - val_loss: 1.6411 - val_accuracy: 0.8158 - 3s/epoch - 4ms/step\n",
            "Epoch 41/50\n",
            "625/625 - 3s - loss: 0.0017 - accuracy: 0.9998 - val_loss: 1.6525 - val_accuracy: 0.8120 - 3s/epoch - 4ms/step\n",
            "Epoch 42/50\n",
            "625/625 - 3s - loss: 0.0027 - accuracy: 0.9994 - val_loss: 1.7402 - val_accuracy: 0.8164 - 3s/epoch - 4ms/step\n",
            "Epoch 43/50\n",
            "625/625 - 3s - loss: 0.0015 - accuracy: 0.9998 - val_loss: 1.7517 - val_accuracy: 0.8148 - 3s/epoch - 4ms/step\n",
            "Epoch 44/50\n",
            "625/625 - 3s - loss: 0.0016 - accuracy: 0.9997 - val_loss: 1.9401 - val_accuracy: 0.8152 - 3s/epoch - 4ms/step\n",
            "Epoch 45/50\n",
            "625/625 - 2s - loss: 6.7501e-04 - accuracy: 0.9999 - val_loss: 1.8285 - val_accuracy: 0.8115 - 2s/epoch - 4ms/step\n",
            "Epoch 46/50\n",
            "625/625 - 3s - loss: 7.4375e-04 - accuracy: 0.9999 - val_loss: 1.8350 - val_accuracy: 0.8112 - 3s/epoch - 4ms/step\n",
            "Epoch 47/50\n",
            "625/625 - 3s - loss: 0.0031 - accuracy: 0.9987 - val_loss: 1.9140 - val_accuracy: 0.8108 - 3s/epoch - 4ms/step\n",
            "Epoch 48/50\n",
            "625/625 - 3s - loss: 7.1847e-04 - accuracy: 0.9998 - val_loss: 1.9137 - val_accuracy: 0.8105 - 3s/epoch - 4ms/step\n",
            "Epoch 49/50\n",
            "625/625 - 3s - loss: 6.2151e-04 - accuracy: 0.9999 - val_loss: 1.9505 - val_accuracy: 0.8108 - 3s/epoch - 4ms/step\n",
            "Epoch 50/50\n",
            "625/625 - 3s - loss: 6.1171e-04 - accuracy: 0.9998 - val_loss: 1.9417 - val_accuracy: 0.8079 - 3s/epoch - 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use trained model\n",
        "sentence = [\n",
        "            \"Granny starting to fear spiders in the garden might be real\",\n",
        "            \"the weather today is bright and sunny\",\n",
        "            \"That's just what I needed today!\",\n",
        "            \"Well, what a surprise.\",\n",
        "            \"Really, Sherlock? No! You are clever.\",\n",
        "            \"Today I had a job interview.\",\n",
        "            \"He went to grab some snacks.\"\n",
        "]\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentence)\n",
        "\n",
        "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "print(model.predict(padded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db9NEnoyFKw6",
        "outputId": "0749a7ce-fd73-45ff-8698-d119b1f5dce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9.9978399e-01]\n",
            " [2.6290691e-06]\n",
            " [9.9676037e-01]\n",
            " [1.3801695e-06]\n",
            " [1.7547780e-10]\n",
            " [9.6333427e-11]\n",
            " [4.0342513e-01]]\n"
          ]
        }
      ]
    }
  ]
}